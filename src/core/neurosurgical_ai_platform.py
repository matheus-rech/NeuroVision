#!/usr/bin/env python3
"""
â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—
â•‘                     CLAUDE NEUROSURGICAL AI PLATFORM - REAL-TIME SYSTEMS                             â•‘
â•‘                                                                                                      â•‘
â•‘  A comprehensive AI platform for neurosurgical applications leveraging Claude's unique capabilities: â•‘
â•‘                                                                                                      â•‘
â•‘  ðŸ”´ REAL-TIME OR SAFETY MONITORING                                                                   â•‘
â•‘     - Streaming frame analysis with sub-second latency simulation                                    â•‘
â•‘     - Contamination detection with severity scoring                                                  â•‘
â•‘     - Sterile field boundary monitoring                                                              â•‘
â•‘     - Instrument tracking and state detection                                                        â•‘
â•‘     - Critical structure proximity alerts                                                            â•‘
â•‘     - Personnel position and role verification                                                       â•‘
â•‘     - Voice-ready alert generation                                                                   â•‘
â•‘                                                                                                      â•‘
â•‘  ðŸŽ“ SURGICAL TRAINING & ASSESSMENT                                                                   â•‘
â•‘     - Real-time technique evaluation                                                                 â•‘
â•‘     - Step-by-step procedure validation                                                              â•‘
â•‘     - Competency scoring with detailed metrics                                                       â•‘
â•‘     - Error detection with corrective feedback                                                       â•‘
â•‘     - Progress tracking across sessions                                                              â•‘
â•‘     - Certification pathway support                                                                  â•‘
â•‘                                                                                                      â•‘
â•‘  ðŸ§­ INTRAOPERATIVE NAVIGATION ASSISTANCE                                                             â•‘
â•‘     - Real-time structure identification                                                             â•‘
â•‘     - Distance-to-target with trajectory guidance                                                    â•‘
â•‘     - Critical structure proximity warnings                                                          â•‘
â•‘     - Surgical phase detection and prediction                                                        â•‘
â•‘     - Anomaly detection (unexpected bleeding, tissue changes)                                        â•‘
â•‘     - Next-step suggestions based on procedure context                                               â•‘
â•‘                                                                                                      â•‘
â•‘  Author: Claude (Anthropic) for Dr. Matheus Machado Rech                                             â•‘
â•‘  Designed to exceed Gemini Robotics-ER capabilities for neurosurgical applications                   â•‘
â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
"""

import asyncio
import json
import time
import random
from dataclasses import dataclass, field, asdict
from typing import List, Dict, Any, Optional, Callable, AsyncIterator, Tuple
from enum import Enum
from datetime import datetime, timedelta
import math


# =============================================================================
# CORE DATA STRUCTURES
# =============================================================================

class AlertSeverity(Enum):
    CRITICAL = "critical"      # Immediate action required - voice alert
    WARNING = "warning"        # Attention needed - visual + audio
    CAUTION = "caution"        # Be aware - visual indicator
    INFO = "info"              # Informational - log only


class SurgicalPhase(Enum):
    PREPARATION = "preparation"
    POSITIONING = "positioning"
    DRAPING = "draping"
    INCISION = "incision"
    EXPOSURE = "exposure"
    APPROACH = "approach"
    RESECTION = "resection"
    HEMOSTASIS = "hemostasis"
    CLOSURE = "closure"
    EMERGENCE = "emergence"


class InstrumentState(Enum):
    IDLE = "idle"
    IN_HAND = "in_hand"
    ACTIVE = "active"
    CONTAMINATED = "contaminated"


@dataclass
class Point2D:
    x: float
    y: float
    
    def distance_to(self, other: 'Point2D') -> float:
        return math.sqrt((self.x - other.x)**2 + (self.y - other.y)**2)
    
    def to_normalized(self) -> Dict:
        """Return as normalized 0-1000 format (Gemini-compatible)."""
        return {"point": [int(self.y * 1000), int(self.x * 1000)]}


@dataclass
class BoundingBox:
    x1: float
    y1: float
    x2: float
    y2: float
    
    def to_normalized(self) -> List[int]:
        """Return as [y1, x1, y2, x2] normalized 0-1000."""
        return [int(self.y1 * 1000), int(self.x1 * 1000), 
                int(self.y2 * 1000), int(self.x2 * 1000)]
    
    def contains(self, point: Point2D) -> bool:
        return self.x1 <= point.x <= self.x2 and self.y1 <= point.y <= self.y2
    
    @property
    def center(self) -> Point2D:
        return Point2D((self.x1 + self.x2) / 2, (self.y1 + self.y2) / 2)


@dataclass
class Alert:
    severity: AlertSeverity
    category: str
    message: str
    location: Optional[Point2D] = None
    bounding_box: Optional[BoundingBox] = None
    timestamp: datetime = field(default_factory=datetime.now)
    voice_message: Optional[str] = None  # Short message for TTS
    action_required: Optional[str] = None
    
    def to_dict(self) -> Dict:
        return {
            "severity": self.severity.value,
            "category": self.category,
            "message": self.message,
            "voice_message": self.voice_message or self.message[:50],
            "action_required": self.action_required,
            "timestamp": self.timestamp.isoformat(),
            "location": self.location.to_normalized() if self.location else None,
            "box_2d": self.bounding_box.to_normalized() if self.bounding_box else None
        }


@dataclass 
class DetectedObject:
    label: str
    confidence: float
    location: Point2D
    bounding_box: Optional[BoundingBox] = None
    category: str = "general"
    metadata: Dict = field(default_factory=dict)
    
    def to_dict(self) -> Dict:
        result = {
            "label": self.label,
            "confidence": round(self.confidence, 3),
            "category": self.category,
            **self.location.to_normalized()
        }
        if self.bounding_box:
            result["box_2d"] = self.bounding_box.to_normalized()
        if self.metadata:
            result["metadata"] = self.metadata
        return result


# =============================================================================
# SECTION 1: REAL-TIME OR SAFETY MONITORING SYSTEM
# =============================================================================

class ORSafetyMonitor:
    """
    Real-time Operating Room Safety Monitoring System.
    
    Provides continuous analysis of OR environment with streaming output
    for low-latency feedback during surgical procedures.
    
    Key Features:
    - Frame-by-frame contamination detection
    - Sterile field boundary monitoring  
    - Instrument tracking and state management
    - Personnel position verification
    - Critical structure proximity alerts
    - Voice-ready alert generation for TTS systems
    """
    
    def __init__(self):
        self.sterile_field = BoundingBox(0.25, 0.25, 0.75, 0.75)  # Central sterile zone
        self.alert_history: List[Alert] = []
        self.frame_count = 0
        self.session_start = datetime.now()
        self.active_alerts: Dict[str, Alert] = {}
        
        # Define critical zones
        self.zones = {
            "sterile_field": BoundingBox(0.25, 0.25, 0.75, 0.75),
            "back_table": BoundingBox(0.02, 0.6, 0.2, 0.95),
            "mayo_stand": BoundingBox(0.15, 0.3, 0.25, 0.5),
            "anesthesia_area": BoundingBox(0.7, 0.02, 0.98, 0.3),
            "traffic_zone": BoundingBox(0.8, 0.3, 0.98, 0.7)
        }
        
        # Personnel tracking
        self.personnel = {}
        self.instrument_states = {}
    
    async def analyze_frame_stream(
        self, 
        frame_data: Dict,
        yield_interval_ms: int = 100
    ) -> AsyncIterator[Dict]:
        """
        Analyze a frame with streaming output for real-time feel.
        
        Yields partial results as they become available, simulating
        the low-latency streaming behavior needed for live OR monitoring.
        """
        self.frame_count += 1
        frame_id = f"frame_{self.frame_count:06d}"
        start_time = time.time()
        
        # Phase 1: Quick safety scan (yield immediately)
        yield {
            "type": "frame_start",
            "frame_id": frame_id,
            "timestamp": datetime.now().isoformat(),
            "status": "analyzing"
        }
        await asyncio.sleep(yield_interval_ms / 1000)
        
        # Phase 2: Contamination detection
        contamination_alerts = await self._detect_contamination(frame_data)
        if contamination_alerts:
            yield {
                "type": "contamination_check",
                "frame_id": frame_id,
                "alerts": [a.to_dict() for a in contamination_alerts],
                "status": "warnings_detected" if contamination_alerts else "clear"
            }
            for alert in contamination_alerts:
                self.alert_history.append(alert)
        await asyncio.sleep(yield_interval_ms / 1000)
        
        # Phase 3: Sterile field monitoring
        field_status = await self._monitor_sterile_field(frame_data)
        yield {
            "type": "sterile_field_status",
            "frame_id": frame_id,
            **field_status
        }
        await asyncio.sleep(yield_interval_ms / 1000)
        
        # Phase 4: Instrument tracking
        instruments = await self._track_instruments(frame_data)
        yield {
            "type": "instrument_tracking",
            "frame_id": frame_id,
            "instruments": instruments,
            "count": len(instruments)
        }
        await asyncio.sleep(yield_interval_ms / 1000)
        
        # Phase 5: Personnel verification
        personnel = await self._verify_personnel(frame_data)
        yield {
            "type": "personnel_status",
            "frame_id": frame_id,
            "personnel": personnel
        }
        await asyncio.sleep(yield_interval_ms / 1000)
        
        # Phase 6: Critical proximity check
        proximity_alerts = await self._check_critical_proximity(frame_data)
        if proximity_alerts:
            yield {
                "type": "proximity_alert",
                "frame_id": frame_id,
                "alerts": [a.to_dict() for a in proximity_alerts]
            }
        
        # Final summary
        processing_time_ms = (time.time() - start_time) * 1000
        all_alerts = contamination_alerts + proximity_alerts
        
        yield {
            "type": "frame_complete",
            "frame_id": frame_id,
            "processing_time_ms": round(processing_time_ms, 2),
            "total_alerts": len(all_alerts),
            "critical_alerts": sum(1 for a in all_alerts if a.severity == AlertSeverity.CRITICAL),
            "safety_score": self._calculate_safety_score(all_alerts),
            "voice_alerts": [a.voice_message for a in all_alerts if a.severity in [AlertSeverity.CRITICAL, AlertSeverity.WARNING]]
        }
    
    async def _detect_contamination(self, frame_data: Dict) -> List[Alert]:
        """Detect contamination events in the frame."""
        alerts = []
        
        # Simulated contamination scenarios based on frame analysis
        contamination_scenarios = frame_data.get("contamination_risks", [])
        
        for risk in contamination_scenarios:
            severity = AlertSeverity[risk.get("severity", "WARNING").upper()]
            alert = Alert(
                severity=severity,
                category="contamination",
                message=risk.get("description", "Potential contamination detected"),
                location=Point2D(risk.get("x", 0.5), risk.get("y", 0.5)),
                voice_message=risk.get("voice", "Contamination warning"),
                action_required=risk.get("action", "Assess and remediate")
            )
            alerts.append(alert)
            self.active_alerts[f"contam_{len(alerts)}"] = alert
        
        return alerts
    
    async def _monitor_sterile_field(self, frame_data: Dict) -> Dict:
        """Monitor sterile field integrity."""
        breaches = []
        
        # Check for objects crossing sterile boundary
        detected_objects = frame_data.get("detected_objects", [])
        for obj in detected_objects:
            if obj.get("category") == "non_sterile":
                loc = Point2D(obj.get("x", 0), obj.get("y", 0))
                if self.sterile_field.contains(loc):
                    breaches.append({
                        "object": obj.get("label"),
                        "location": loc.to_normalized(),
                        "severity": "critical"
                    })
        
        return {
            "integrity": "compromised" if breaches else "intact",
            "breaches": breaches,
            "boundary": self.sterile_field.to_normalized()
        }
    
    async def _track_instruments(self, frame_data: Dict) -> List[Dict]:
        """Track surgical instruments and their states."""
        instruments = []
        
        instrument_data = frame_data.get("instruments", [])
        for inst in instrument_data:
            inst_id = inst.get("id", inst.get("label"))
            state = InstrumentState[inst.get("state", "IDLE").upper()]
            
            self.instrument_states[inst_id] = {
                "state": state,
                "last_seen": datetime.now(),
                "location": inst.get("location")
            }
            
            instruments.append({
                "label": inst.get("label"),
                "state": state.value,
                "point": [int(inst.get("y", 0.5) * 1000), int(inst.get("x", 0.5) * 1000)],
                "in_sterile_field": self.sterile_field.contains(
                    Point2D(inst.get("x", 0), inst.get("y", 0))
                ),
                "confidence": inst.get("confidence", 0.9)
            })
        
        return instruments
    
    async def _verify_personnel(self, frame_data: Dict) -> Dict:
        """Verify personnel positions and roles."""
        personnel = frame_data.get("personnel", [])
        verified = []
        concerns = []
        
        for person in personnel:
            role = person.get("role", "unknown")
            location = Point2D(person.get("x", 0), person.get("y", 0))
            is_scrubbed = person.get("scrubbed", False)
            
            # Check if non-scrubbed personnel in sterile area
            if not is_scrubbed and self.sterile_field.contains(location):
                concerns.append({
                    "role": role,
                    "issue": "Non-scrubbed personnel in sterile field",
                    "severity": "critical"
                })
            
            verified.append({
                "role": role,
                "scrubbed": is_scrubbed,
                "position_valid": self._validate_personnel_position(role, location),
                "point": location.to_normalized()["point"]
            })
        
        return {
            "count": len(verified),
            "verified": verified,
            "concerns": concerns
        }
    
    def _validate_personnel_position(self, role: str, location: Point2D) -> bool:
        """Validate that personnel are in appropriate positions."""
        role_zones = {
            "surgeon": "sterile_field",
            "first_assistant": "sterile_field", 
            "scrub_nurse": "sterile_field",
            "circulator": "traffic_zone",
            "anesthesiologist": "anesthesia_area"
        }
        expected_zone = role_zones.get(role.lower())
        if expected_zone and expected_zone in self.zones:
            return self.zones[expected_zone].contains(location)
        return True
    
    async def _check_critical_proximity(self, frame_data: Dict) -> List[Alert]:
        """Check proximity to critical anatomical structures."""
        alerts = []
        
        critical_structures = frame_data.get("critical_structures", [])
        instrument_tips = frame_data.get("instrument_tips", [])
        
        for struct in critical_structures:
            struct_loc = Point2D(struct.get("x", 0), struct.get("y", 0))
            safety_margin = struct.get("safety_margin", 0.05)  # 5% of field
            
            for tip in instrument_tips:
                tip_loc = Point2D(tip.get("x", 0), tip.get("y", 0))
                distance = struct_loc.distance_to(tip_loc)
                
                if distance < safety_margin:
                    severity = AlertSeverity.CRITICAL if distance < safety_margin / 2 else AlertSeverity.WARNING
                    alert = Alert(
                        severity=severity,
                        category="proximity",
                        message=f"{tip.get('label', 'Instrument')} within {distance*100:.1f}cm of {struct.get('label', 'critical structure')}",
                        location=tip_loc,
                        voice_message=f"Warning: proximity to {struct.get('label', 'critical structure')}",
                        action_required="Increase distance or proceed with extreme caution"
                    )
                    alerts.append(alert)
        
        return alerts
    
    def _calculate_safety_score(self, alerts: List[Alert]) -> float:
        """Calculate overall safety score (0-100)."""
        if not alerts:
            return 100.0
        
        penalty = 0
        for alert in alerts:
            if alert.severity == AlertSeverity.CRITICAL:
                penalty += 25
            elif alert.severity == AlertSeverity.WARNING:
                penalty += 10
            elif alert.severity == AlertSeverity.CAUTION:
                penalty += 5
        
        return max(0, 100 - penalty)
    
    def get_session_summary(self) -> Dict:
        """Get summary of monitoring session."""
        duration = datetime.now() - self.session_start
        
        severity_counts = {s.value: 0 for s in AlertSeverity}
        for alert in self.alert_history:
            severity_counts[alert.severity.value] += 1
        
        return {
            "session_duration_seconds": duration.total_seconds(),
            "total_frames_analyzed": self.frame_count,
            "total_alerts": len(self.alert_history),
            "alerts_by_severity": severity_counts,
            "average_safety_score": self._calculate_average_safety(),
            "instruments_tracked": len(self.instrument_states),
            "personnel_tracked": len(self.personnel)
        }
    
    def _calculate_average_safety(self) -> float:
        """Calculate average safety score across session."""
        if not self.alert_history:
            return 100.0
        # Simplified - in production would track per-frame scores
        return max(0, 100 - len(self.alert_history) * 2)


# =============================================================================
# SECTION 2: SURGICAL TRAINING & ASSESSMENT SYSTEM
# =============================================================================

@dataclass
class ProcedureStep:
    """Definition of a single step in a surgical procedure."""
    step_number: int
    name: str
    description: str
    critical: bool = False
    time_limit_seconds: Optional[int] = None
    required_instruments: List[str] = field(default_factory=list)
    safety_checks: List[str] = field(default_factory=list)
    common_errors: List[str] = field(default_factory=list)
    assessment_criteria: Dict[str, float] = field(default_factory=dict)  # criterion -> weight


@dataclass
class PerformanceMetrics:
    """Metrics for assessing trainee performance."""
    accuracy_score: float = 0.0      # 0-100
    efficiency_score: float = 0.0    # 0-100  
    safety_score: float = 0.0        # 0-100
    technique_score: float = 0.0     # 0-100
    time_score: float = 0.0          # 0-100
    
    @property
    def overall_score(self) -> float:
        weights = {
            "accuracy": 0.25,
            "efficiency": 0.15,
            "safety": 0.30,
            "technique": 0.20,
            "time": 0.10
        }
        return (
            self.accuracy_score * weights["accuracy"] +
            self.efficiency_score * weights["efficiency"] +
            self.safety_score * weights["safety"] +
            self.technique_score * weights["technique"] +
            self.time_score * weights["time"]
        )
    
    @property
    def grade(self) -> str:
        score = self.overall_score
        if score >= 90: return "A - Excellent"
        elif score >= 80: return "B - Proficient"
        elif score >= 70: return "C - Competent"
        elif score >= 60: return "D - Developing"
        else: return "F - Needs Improvement"


class SurgicalTrainingSystem:
    """
    Comprehensive Surgical Training and Assessment System.
    
    Provides real-time feedback during simulated or supervised procedures,
    tracks trainee progress, and generates detailed competency assessments.
    """
    
    # Pre-defined procedure libraries
    PROCEDURE_LIBRARY = {
        "craniotomy_tumor_resection": [
            ProcedureStep(1, "Patient Positioning", "Position patient with head in Mayfield clamp",
                         critical=True, required_instruments=["Mayfield clamp", "gel rolls"],
                         safety_checks=["Pressure points padded", "Eyes protected", "Arms secured"],
                         assessment_criteria={"head_stability": 0.4, "neutral_position": 0.3, "access_adequate": 0.3}),
            ProcedureStep(2, "Skin Incision", "Mark and incise along planned trajectory",
                         required_instruments=["Surgical marker", "Scalpel #10", "Bovie"],
                         common_errors=["Incision too short", "Deviation from midline"],
                         assessment_criteria={"incision_accuracy": 0.5, "hemostasis": 0.3, "tissue_handling": 0.2}),
            ProcedureStep(3, "Craniotomy", "Perform bone flap elevation",
                         critical=True, required_instruments=["Perforator", "Craniotome", "Penfield #3"],
                         safety_checks=["Dura protected", "Venous sinuses avoided"],
                         assessment_criteria={"bone_cut_precision": 0.3, "dura_integrity": 0.4, "efficiency": 0.3}),
            ProcedureStep(4, "Dural Opening", "Open dura in cruciate fashion",
                         required_instruments=["Dural scissors", "Bipolar", "4-0 Nurolon"],
                         safety_checks=["Cortical vessels preserved", "Brain relaxed"],
                         assessment_criteria={"dural_preservation": 0.3, "vessel_protection": 0.4, "exposure": 0.3}),
            ProcedureStep(5, "Tumor Identification", "Identify tumor margins using navigation",
                         required_instruments=["Navigation pointer", "Ultrasound probe"],
                         assessment_criteria={"margin_accuracy": 0.5, "navigation_use": 0.3, "planning": 0.2}),
            ProcedureStep(6, "Tumor Resection", "Systematic tumor removal",
                         critical=True, required_instruments=["CUSA", "Bipolar", "Suction"],
                         safety_checks=["Eloquent cortex protected", "Vessels preserved"],
                         common_errors=["Residual tumor", "Eloquent cortex injury", "Vascular injury"],
                         assessment_criteria={"extent_of_resection": 0.3, "safety": 0.4, "technique": 0.3}),
            ProcedureStep(7, "Hemostasis", "Achieve complete hemostasis",
                         required_instruments=["Bipolar", "Surgicel", "Gelfoam"],
                         assessment_criteria={"bleeding_control": 0.5, "minimal_coagulation": 0.3, "inspection": 0.2}),
            ProcedureStep(8, "Closure", "Close dura and replace bone flap",
                         required_instruments=["4-0 Nurolon", "Cranial plates", "Drill"],
                         assessment_criteria={"watertight_closure": 0.4, "cosmesis": 0.3, "efficiency": 0.3})
        ],
        "transsphenoidal_pituitary": [
            ProcedureStep(1, "Nasal Preparation", "Prepare nasal cavity with vasoconstrictors",
                         required_instruments=["Nasal speculum", "Cottonoids with epinephrine"],
                         assessment_criteria={"hemostasis": 0.5, "visualization": 0.5}),
            ProcedureStep(2, "Nasal Approach", "Establish corridor to sphenoid",
                         required_instruments=["Endoscope", "Suction", "Freer elevator"],
                         safety_checks=["Turbinates preserved", "Septum intact"],
                         assessment_criteria={"tissue_preservation": 0.4, "corridor_width": 0.3, "bleeding_control": 0.3}),
            ProcedureStep(3, "Sphenoidotomy", "Open sphenoid sinus",
                         required_instruments=["Kerrison rongeur", "High-speed drill"],
                         safety_checks=["Carotid identified", "Optic nerve protected"],
                         assessment_criteria={"bone_removal": 0.3, "safety": 0.5, "exposure": 0.2}),
            ProcedureStep(4, "Sellar Opening", "Open sellar floor and dura",
                         critical=True, required_instruments=["Micro-Kerrison", "Dural knife"],
                         safety_checks=["ICA lateral margins identified", "CSF leak controlled"],
                         assessment_criteria={"precision": 0.4, "safety": 0.4, "exposure": 0.2}),
            ProcedureStep(5, "Tumor Resection", "Remove pituitary tumor",
                         critical=True, required_instruments=["Ring curettes", "Suction", "Angled endoscope"],
                         common_errors=["Residual tumor in cavernous sinus", "Diaphragm injury"],
                         assessment_criteria={"extent_of_resection": 0.4, "technique": 0.3, "safety": 0.3}),
            ProcedureStep(6, "Reconstruction", "Sellar floor reconstruction",
                         required_instruments=["Fat graft", "Fascia", "Tissue sealant"],
                         assessment_criteria={"leak_prevention": 0.5, "technique": 0.3, "efficiency": 0.2})
        ],
        "dbs_lead_placement": [
            ProcedureStep(1, "Frame Placement", "Apply stereotactic frame",
                         critical=True, required_instruments=["Leksell frame", "Frame pins"],
                         safety_checks=["Parallel to AC-PC line", "Symmetric placement"],
                         assessment_criteria={"accuracy": 0.5, "patient_comfort": 0.3, "efficiency": 0.2}),
            ProcedureStep(2, "Trajectory Planning", "Plan electrode trajectory",
                         required_instruments=["Planning workstation"],
                         safety_checks=["Ventricle avoided", "Vessels avoided", "Sulci followed"],
                         assessment_criteria={"target_accuracy": 0.4, "safety_margin": 0.4, "efficiency": 0.2}),
            ProcedureStep(3, "Burr Hole", "Create burr hole at entry point",
                         required_instruments=["14mm perforator", "Bipolar"],
                         assessment_criteria={"location_accuracy": 0.5, "dura_preservation": 0.3, "efficiency": 0.2}),
            ProcedureStep(4, "MER Recording", "Perform microelectrode recording",
                         critical=True, required_instruments=["MER system", "Microelectrodes"],
                         assessment_criteria={"signal_quality": 0.4, "track_selection": 0.4, "efficiency": 0.2}),
            ProcedureStep(5, "Lead Implantation", "Implant DBS lead at target",
                         critical=True, required_instruments=["DBS lead", "Guide tube", "Fluoroscopy"],
                         safety_checks=["Depth verified", "Position confirmed"],
                         assessment_criteria={"target_accuracy": 0.5, "lead_integrity": 0.3, "technique": 0.2}),
            ProcedureStep(6, "Test Stimulation", "Perform intraoperative testing",
                         required_instruments=["Programmer", "Impedance tester"],
                         assessment_criteria={"therapeutic_window": 0.5, "side_effect_threshold": 0.3, "documentation": 0.2})
        ]
    }
    
    def __init__(self, trainee_id: str, procedure_type: str):
        self.trainee_id = trainee_id
        self.procedure_type = procedure_type
        self.procedure_steps = self.PROCEDURE_LIBRARY.get(procedure_type, [])
        self.current_step_index = 0
        self.session_start = datetime.now()
        self.step_times: List[float] = []
        self.step_scores: List[PerformanceMetrics] = []
        self.errors_detected: List[Dict] = []
        self.feedback_history: List[Dict] = []
        
    async def analyze_step_stream(
        self, 
        frame_data: Dict,
        yield_interval_ms: int = 150
    ) -> AsyncIterator[Dict]:
        """
        Analyze trainee performance on current step with streaming feedback.
        
        Provides real-time assessment and guidance during training procedures.
        """
        current_step = self.procedure_steps[self.current_step_index]
        analysis_start = time.time()
        
        # Phase 1: Identify current action
        yield {
            "type": "step_analysis_start",
            "current_step": current_step.name,
            "step_number": current_step.step_number,
            "is_critical": current_step.critical
        }
        await asyncio.sleep(yield_interval_ms / 1000)
        
        # Phase 2: Check required instruments
        instruments_check = await self._check_instruments(frame_data, current_step)
        yield {
            "type": "instrument_check",
            **instruments_check
        }
        await asyncio.sleep(yield_interval_ms / 1000)
        
        # Phase 3: Safety verification
        if current_step.safety_checks:
            safety_status = await self._verify_safety_checks(frame_data, current_step)
            yield {
                "type": "safety_verification",
                **safety_status
            }
            await asyncio.sleep(yield_interval_ms / 1000)
        
        # Phase 4: Technique assessment
        technique_assessment = await self._assess_technique(frame_data, current_step)
        yield {
            "type": "technique_assessment",
            **technique_assessment
        }
        await asyncio.sleep(yield_interval_ms / 1000)
        
        # Phase 5: Error detection
        errors = await self._detect_errors(frame_data, current_step)
        if errors:
            yield {
                "type": "error_detection",
                "errors": errors,
                "corrections": [self._get_correction_guidance(e) for e in errors]
            }
            self.errors_detected.extend(errors)
        await asyncio.sleep(yield_interval_ms / 1000)
        
        # Phase 6: Real-time feedback
        feedback = self._generate_realtime_feedback(
            instruments_check, 
            technique_assessment, 
            errors
        )
        yield {
            "type": "realtime_feedback",
            "feedback": feedback,
            "voice_guidance": feedback.get("voice_message")
        }
        
        # Phase 7: Step completion check
        step_complete, completion_score = await self._check_step_completion(frame_data, current_step)
        
        analysis_time = time.time() - analysis_start
        
        yield {
            "type": "step_analysis_complete",
            "step_complete": step_complete,
            "completion_score": completion_score,
            "analysis_time_ms": round(analysis_time * 1000, 2),
            "can_proceed": step_complete and completion_score >= 70
        }
        
        if step_complete:
            metrics = PerformanceMetrics(
                accuracy_score=technique_assessment.get("accuracy", 80),
                efficiency_score=technique_assessment.get("efficiency", 75),
                safety_score=100 - len(errors) * 15,
                technique_score=technique_assessment.get("technique", 80),
                time_score=self._calculate_time_score(analysis_time, current_step)
            )
            self.step_scores.append(metrics)
            self.step_times.append(analysis_time)
    
    async def _check_instruments(self, frame_data: Dict, step: ProcedureStep) -> Dict:
        """Check if required instruments are present and properly positioned."""
        detected = frame_data.get("instruments", [])
        detected_labels = [i.get("label", "").lower() for i in detected]
        
        required = step.required_instruments
        present = []
        missing = []
        
        for req in required:
            if any(req.lower() in label for label in detected_labels):
                present.append(req)
            else:
                missing.append(req)
        
        return {
            "required": required,
            "present": present,
            "missing": missing,
            "all_ready": len(missing) == 0
        }
    
    async def _verify_safety_checks(self, frame_data: Dict, step: ProcedureStep) -> Dict:
        """Verify that safety requirements are met."""
        checks = step.safety_checks
        results = []
        
        for check in checks:
            # In production, this would analyze frame data for each specific check
            passed = random.random() > 0.15  # Simulated - 85% pass rate
            results.append({
                "check": check,
                "passed": passed,
                "severity": "critical" if not passed and step.critical else "warning"
            })
        
        all_passed = all(r["passed"] for r in results)
        
        return {
            "checks": results,
            "all_passed": all_passed,
            "proceed_allowed": all_passed or not step.critical
        }
    
    async def _assess_technique(self, frame_data: Dict, step: ProcedureStep) -> Dict:
        """Assess surgical technique quality."""
        # Simulated technique assessment based on frame analysis
        criteria = step.assessment_criteria
        scores = {}
        
        for criterion, weight in criteria.items():
            # In production, each criterion would have specific analysis logic
            score = random.uniform(70, 98)  # Simulated scores
            scores[criterion] = round(score, 1)
        
        weighted_total = sum(
            scores[c] * criteria[c] for c in criteria
        )
        
        return {
            "criteria_scores": scores,
            "weighted_score": round(weighted_total, 1),
            "accuracy": round(random.uniform(75, 95), 1),
            "efficiency": round(random.uniform(70, 90), 1),
            "technique": round(weighted_total, 1)
        }
    
    async def _detect_errors(self, frame_data: Dict, step: ProcedureStep) -> List[Dict]:
        """Detect common errors in current step."""
        errors = []
        
        for common_error in step.common_errors:
            # In production, specific detection logic for each error type
            if random.random() < 0.1:  # 10% simulated error rate
                errors.append({
                    "error_type": common_error,
                    "severity": "major" if step.critical else "minor",
                    "timestamp": datetime.now().isoformat()
                })
        
        return errors
    
    def _get_correction_guidance(self, error: Dict) -> str:
        """Generate correction guidance for detected error."""
        error_guidance = {
            "Incision too short": "Extend incision 1-2cm to improve exposure",
            "Deviation from midline": "Use navigation to verify trajectory, correct course",
            "Residual tumor": "Use angled endoscope to inspect margins, continue resection",
            "Eloquent cortex injury": "Stop resection, assess function with stimulation",
            "Vascular injury": "Apply gentle pressure, prepare for bipolar coagulation",
            "Diaphragm injury": "Prepare for fat graft and fascia reconstruction"
        }
        return error_guidance.get(error["error_type"], "Review technique and proceed with caution")
    
    def _generate_realtime_feedback(
        self, 
        instruments: Dict, 
        technique: Dict, 
        errors: List[Dict]
    ) -> Dict:
        """Generate real-time feedback for trainee."""
        messages = []
        voice_message = None
        
        # Instrument feedback
        if instruments.get("missing"):
            missing = instruments["missing"]
            messages.append(f"Missing instruments: {', '.join(missing)}")
            voice_message = f"Please prepare {missing[0]}"
        
        # Technique feedback
        score = technique.get("weighted_score", 80)
        if score >= 90:
            messages.append("Excellent technique - maintain this standard")
        elif score >= 75:
            messages.append("Good technique - minor improvements possible")
        else:
            messages.append("Technique needs improvement - slow down and focus")
            if not voice_message:
                voice_message = "Slow down and focus on technique"
        
        # Error feedback
        if errors:
            for error in errors:
                messages.append(f"Error detected: {error['error_type']}")
            if not voice_message:
                voice_message = f"Attention: {errors[0]['error_type']}"
        
        return {
            "messages": messages,
            "voice_message": voice_message,
            "overall_status": "needs_attention" if errors or score < 70 else "on_track"
        }
    
    async def _check_step_completion(self, frame_data: Dict, step: ProcedureStep) -> Tuple[bool, float]:
        """Check if current step is complete."""
        # In production, specific completion criteria for each step
        completion_indicators = frame_data.get("completion_indicators", {})
        
        # Simulated completion check
        is_complete = completion_indicators.get("step_complete", random.random() > 0.7)
        score = completion_indicators.get("score", random.uniform(70, 95))
        
        return is_complete, round(score, 1)
    
    def _calculate_time_score(self, actual_time: float, step: ProcedureStep) -> float:
        """Calculate time efficiency score."""
        if step.time_limit_seconds:
            if actual_time <= step.time_limit_seconds:
                return 100.0
            elif actual_time <= step.time_limit_seconds * 1.5:
                return 80.0
            else:
                return 60.0
        return 85.0  # Default score if no time limit
    
    def advance_step(self) -> Optional[ProcedureStep]:
        """Advance to next step if possible."""
        if self.current_step_index < len(self.procedure_steps) - 1:
            self.current_step_index += 1
            return self.procedure_steps[self.current_step_index]
        return None
    
    def get_session_report(self) -> Dict:
        """Generate comprehensive session report."""
        if not self.step_scores:
            return {"error": "No steps completed"}
        
        avg_metrics = PerformanceMetrics(
            accuracy_score=sum(s.accuracy_score for s in self.step_scores) / len(self.step_scores),
            efficiency_score=sum(s.efficiency_score for s in self.step_scores) / len(self.step_scores),
            safety_score=sum(s.safety_score for s in self.step_scores) / len(self.step_scores),
            technique_score=sum(s.technique_score for s in self.step_scores) / len(self.step_scores),
            time_score=sum(s.time_score for s in self.step_scores) / len(self.step_scores)
        )
        
        return {
            "trainee_id": self.trainee_id,
            "procedure": self.procedure_type,
            "date": self.session_start.isoformat(),
            "duration_minutes": (datetime.now() - self.session_start).total_seconds() / 60,
            "steps_completed": len(self.step_scores),
            "total_steps": len(self.procedure_steps),
            "overall_score": round(avg_metrics.overall_score, 1),
            "grade": avg_metrics.grade,
            "metrics": {
                "accuracy": round(avg_metrics.accuracy_score, 1),
                "efficiency": round(avg_metrics.efficiency_score, 1),
                "safety": round(avg_metrics.safety_score, 1),
                "technique": round(avg_metrics.technique_score, 1),
                "time": round(avg_metrics.time_score, 1)
            },
            "errors_detected": len(self.errors_detected),
            "error_details": self.errors_detected,
            "recommendations": self._generate_recommendations(avg_metrics),
            "certification_eligible": avg_metrics.overall_score >= 80 and avg_metrics.safety_score >= 85
        }
    
    def _generate_recommendations(self, metrics: PerformanceMetrics) -> List[str]:
        """Generate personalized recommendations based on performance."""
        recommendations = []
        
        if metrics.safety_score < 85:
            recommendations.append("Focus on safety protocols - review critical structure identification")
        if metrics.technique_score < 80:
            recommendations.append("Practice microsurgical technique - consider simulation training")
        if metrics.efficiency_score < 75:
            recommendations.append("Improve procedural flow - review step sequencing")
        if metrics.accuracy_score < 80:
            recommendations.append("Enhance precision - practice with navigation systems")
        if metrics.time_score < 75:
            recommendations.append("Work on time management - identify bottlenecks")
        
        if not recommendations:
            recommendations.append("Excellent performance - ready for increased autonomy")
        
        return recommendations


# =============================================================================
# SECTION 3: INTRAOPERATIVE NAVIGATION ASSISTANCE
# =============================================================================

class IntraoperativeNavigationAssistant:
    """
    Real-time Intraoperative Navigation Assistance System.
    
    Provides continuous guidance during neurosurgical procedures including:
    - Structure identification with confidence scores
    - Distance-to-target calculations
    - Critical structure proximity warnings
    - Surgical phase detection
    - Anomaly detection (bleeding, tissue changes)
    - Next-step suggestions
    """
    
    def __init__(self, procedure_type: str, planned_trajectory: Optional[Dict] = None):
        self.procedure_type = procedure_type
        self.planned_trajectory = planned_trajectory
        self.current_phase = SurgicalPhase.PREPARATION
        self.phase_history: List[Tuple[SurgicalPhase, datetime]] = [(SurgicalPhase.PREPARATION, datetime.now())]
        self.identified_structures: Dict[str, DetectedObject] = {}
        self.critical_alerts: List[Alert] = []
        self.navigation_accuracy_mm = 1.5  # Assumed accuracy
        
        # Define procedure-specific critical structures
        self.critical_structures = self._get_procedure_critical_structures()
    
    def _get_procedure_critical_structures(self) -> Dict[str, Dict]:
        """Get critical structures based on procedure type."""
        structures = {
            "craniotomy": {
                "motor_cortex": {"safety_margin_mm": 10, "severity": "critical"},
                "sensory_cortex": {"safety_margin_mm": 8, "severity": "critical"},
                "language_area": {"safety_margin_mm": 10, "severity": "critical"},
                "cortical_vein": {"safety_margin_mm": 3, "severity": "warning"},
                "bridging_vein": {"safety_margin_mm": 5, "severity": "critical"},
                "mca_branch": {"safety_margin_mm": 2, "severity": "critical"}
            },
            "transsphenoidal": {
                "internal_carotid": {"safety_margin_mm": 3, "severity": "critical"},
                "optic_nerve": {"safety_margin_mm": 2, "severity": "critical"},
                "optic_chiasm": {"safety_margin_mm": 3, "severity": "critical"},
                "cavernous_sinus": {"safety_margin_mm": 2, "severity": "warning"},
                "diaphragma_sellae": {"safety_margin_mm": 1, "severity": "warning"}
            },
            "dbs": {
                "internal_capsule": {"safety_margin_mm": 2, "severity": "critical"},
                "lateral_ventricle": {"safety_margin_mm": 3, "severity": "warning"},
                "thalamus": {"safety_margin_mm": 2, "severity": "warning"},
                "red_nucleus": {"safety_margin_mm": 2, "severity": "caution"}
            },
            "posterior_fossa": {
                "brainstem": {"safety_margin_mm": 3, "severity": "critical"},
                "fourth_ventricle": {"safety_margin_mm": 2, "severity": "warning"},
                "vertebral_artery": {"safety_margin_mm": 2, "severity": "critical"},
                "pica": {"safety_margin_mm": 2, "severity": "critical"},
                "facial_nerve": {"safety_margin_mm": 2, "severity": "critical"},
                "cochlear_nerve": {"safety_margin_mm": 2, "severity": "critical"}
            }
        }
        
        # Default to craniotomy if procedure not found
        proc_key = "craniotomy"
        for key in structures:
            if key in self.procedure_type.lower():
                proc_key = key
                break
        
        return structures[proc_key]
    
    async def analyze_navigation_frame(
        self, 
        frame_data: Dict,
        yield_interval_ms: int = 80
    ) -> AsyncIterator[Dict]:
        """
        Analyze frame for navigation assistance with streaming output.
        
        Provides real-time guidance optimized for low-latency intraoperative use.
        """
        frame_start = time.time()
        
        # Phase 1: Quick structure scan
        yield {
            "type": "nav_frame_start",
            "timestamp": datetime.now().isoformat(),
            "current_phase": self.current_phase.value
        }
        await asyncio.sleep(yield_interval_ms / 1000)
        
        # Phase 2: Structure identification
        structures = await self._identify_structures(frame_data)
        yield {
            "type": "structure_identification",
            "structures": [s.to_dict() for s in structures],
            "count": len(structures)
        }
        await asyncio.sleep(yield_interval_ms / 1000)
        
        # Phase 3: Distance calculations (if target defined)
        if self.planned_trajectory:
            distances = await self._calculate_distances(frame_data)
            yield {
                "type": "distance_update",
                **distances
            }
            await asyncio.sleep(yield_interval_ms / 1000)
        
        # Phase 4: Critical proximity check
        proximity_status = await self._check_critical_proximity(frame_data)
        if proximity_status["alerts"]:
            yield {
                "type": "proximity_warning",
                **proximity_status,
                "voice_alert": proximity_status.get("voice_message")
            }
        else:
            yield {
                "type": "proximity_clear",
                "status": "safe",
                "nearest_critical": proximity_status.get("nearest")
            }
        await asyncio.sleep(yield_interval_ms / 1000)
        
        # Phase 5: Phase detection
        phase_update = await self._detect_surgical_phase(frame_data)
        if phase_update["phase_changed"]:
            yield {
                "type": "phase_change",
                **phase_update
            }
        await asyncio.sleep(yield_interval_ms / 1000)
        
        # Phase 6: Anomaly detection
        anomalies = await self._detect_anomalies(frame_data)
        if anomalies:
            yield {
                "type": "anomaly_detected",
                "anomalies": anomalies,
                "voice_alert": anomalies[0].get("voice_message") if anomalies else None
            }
        await asyncio.sleep(yield_interval_ms / 1000)
        
        # Phase 7: Next step suggestion
        suggestion = await self._generate_next_step_suggestion(frame_data)
        yield {
            "type": "guidance",
            "suggestion": suggestion["next_step"],
            "confidence": suggestion["confidence"],
            "rationale": suggestion["rationale"]
        }
        
        # Summary
        processing_time = time.time() - frame_start
        yield {
            "type": "nav_frame_complete",
            "processing_time_ms": round(processing_time * 1000, 2),
            "navigation_accuracy_mm": self.navigation_accuracy_mm,
            "structures_tracked": len(self.identified_structures),
            "active_warnings": len([a for a in self.critical_alerts if a.severity == AlertSeverity.CRITICAL])
        }
    
    async def _identify_structures(self, frame_data: Dict) -> List[DetectedObject]:
        """Identify anatomical structures in frame."""
        structures = []
        
        detected = frame_data.get("anatomical_structures", [])
        for struct in detected:
            obj = DetectedObject(
                label=struct.get("label", "unknown"),
                confidence=struct.get("confidence", 0.8),
                location=Point2D(struct.get("x", 0.5), struct.get("y", 0.5)),
                bounding_box=BoundingBox(
                    struct.get("x1", 0.4), struct.get("y1", 0.4),
                    struct.get("x2", 0.6), struct.get("y2", 0.6)
                ) if struct.get("has_bbox") else None,
                category=struct.get("category", "anatomy"),
                metadata=struct.get("metadata", {})
            )
            structures.append(obj)
            self.identified_structures[obj.label] = obj
        
        return structures
    
    async def _calculate_distances(self, frame_data: Dict) -> Dict:
        """Calculate distances to target and trajectory."""
        instrument_tip = frame_data.get("instrument_tip", {})
        target = self.planned_trajectory.get("target", {})
        
        if not instrument_tip or not target:
            return {"status": "no_data"}
        
        tip_loc = Point2D(instrument_tip.get("x", 0), instrument_tip.get("y", 0))
        target_loc = Point2D(target.get("x", 0), target.get("y", 0))
        
        distance_to_target = tip_loc.distance_to(target_loc) * 100  # Scale to mm approximation
        
        # Calculate trajectory deviation
        entry = self.planned_trajectory.get("entry", {})
        if entry:
            entry_loc = Point2D(entry.get("x", 0), entry.get("y", 0))
            # Simplified deviation calculation
            deviation = self._calculate_trajectory_deviation(tip_loc, entry_loc, target_loc)
        else:
            deviation = 0
        
        return {
            "distance_to_target_mm": round(distance_to_target, 1),
            "trajectory_deviation_mm": round(deviation, 1),
            "on_trajectory": deviation < 2.0,
            "depth_percentage": self._estimate_depth_percentage(tip_loc, entry_loc if entry else None, target_loc)
        }
    
    def _calculate_trajectory_deviation(self, current: Point2D, entry: Point2D, target: Point2D) -> float:
        """Calculate perpendicular deviation from planned trajectory."""
        # Vector from entry to target
        dx = target.x - entry.x
        dy = target.y - entry.y
        length = math.sqrt(dx*dx + dy*dy)
        
        if length < 0.001:
            return 0
        
        # Normalized direction
        dx /= length
        dy /= length
        
        # Vector from entry to current
        px = current.x - entry.x
        py = current.y - entry.y
        
        # Project onto trajectory
        proj = px * dx + py * dy
        
        # Perpendicular distance
        perp_x = px - proj * dx
        perp_y = py - proj * dy
        
        return math.sqrt(perp_x*perp_x + perp_y*perp_y) * 100  # Scale to mm
    
    def _estimate_depth_percentage(self, current: Point2D, entry: Optional[Point2D], target: Point2D) -> float:
        """Estimate percentage of trajectory completed."""
        if not entry:
            return 0
        
        total_dist = entry.distance_to(target)
        current_dist = entry.distance_to(current)
        
        if total_dist < 0.001:
            return 100
        
        return min(100, max(0, (current_dist / total_dist) * 100))
    
    async def _check_critical_proximity(self, frame_data: Dict) -> Dict:
        """Check proximity to all critical structures."""
        alerts = []
        nearest = None
        min_distance = float('inf')
        
        instrument_tip = frame_data.get("instrument_tip", {})
        if not instrument_tip:
            return {"alerts": [], "status": "no_instrument_detected"}
        
        tip_loc = Point2D(instrument_tip.get("x", 0.5), instrument_tip.get("y", 0.5))
        
        for struct_name, struct_info in self.critical_structures.items():
            # Check if structure is in frame
            struct_data = frame_data.get("critical_structures", {}).get(struct_name)
            if struct_data:
                struct_loc = Point2D(struct_data.get("x", 0.5), struct_data.get("y", 0.5))
                distance = tip_loc.distance_to(struct_loc) * 100  # Scale to mm approximation
                
                if distance < min_distance:
                    min_distance = distance
                    nearest = {"structure": struct_name, "distance_mm": round(distance, 1)}
                
                safety_margin = struct_info["safety_margin_mm"]
                if distance < safety_margin:
                    severity = AlertSeverity[struct_info["severity"].upper()]
                    alert = Alert(
                        severity=severity,
                        category="critical_proximity",
                        message=f"Within {distance:.1f}mm of {struct_name}",
                        location=tip_loc,
                        voice_message=f"Warning: {struct_name}" if severity == AlertSeverity.CRITICAL else None,
                        action_required=f"Increase distance, margin is {safety_margin}mm"
                    )
                    alerts.append(alert)
                    self.critical_alerts.append(alert)
        
        return {
            "alerts": [a.to_dict() for a in alerts],
            "nearest": nearest,
            "voice_message": alerts[0].voice_message if alerts else None
        }
    
    async def _detect_surgical_phase(self, frame_data: Dict) -> Dict:
        """Detect current surgical phase based on frame analysis."""
        indicators = frame_data.get("phase_indicators", {})
        
        # Phase detection logic based on visual indicators
        detected_phase = self.current_phase
        confidence = 0.7
        
        if indicators.get("dura_visible") and not indicators.get("dura_opened"):
            detected_phase = SurgicalPhase.EXPOSURE
            confidence = 0.85
        elif indicators.get("tumor_visible"):
            detected_phase = SurgicalPhase.RESECTION
            confidence = 0.9
        elif indicators.get("active_bleeding"):
            detected_phase = SurgicalPhase.HEMOSTASIS
            confidence = 0.88
        elif indicators.get("closure_started"):
            detected_phase = SurgicalPhase.CLOSURE
            confidence = 0.92
        
        phase_changed = detected_phase != self.current_phase
        if phase_changed:
            self.current_phase = detected_phase
            self.phase_history.append((detected_phase, datetime.now()))
        
        return {
            "current_phase": detected_phase.value,
            "phase_changed": phase_changed,
            "previous_phase": self.phase_history[-2][0].value if len(self.phase_history) > 1 and phase_changed else None,
            "confidence": confidence,
            "phase_duration_seconds": (datetime.now() - self.phase_history[-1][1]).total_seconds()
        }
    
    async def _detect_anomalies(self, frame_data: Dict) -> List[Dict]:
        """Detect anomalies requiring attention."""
        anomalies = []
        
        # Check for unexpected bleeding
        if frame_data.get("bleeding_detected"):
            bleeding_info = frame_data["bleeding_detected"]
            anomalies.append({
                "type": "unexpected_bleeding",
                "severity": bleeding_info.get("severity", "moderate"),
                "location": bleeding_info.get("location"),
                "voice_message": "Bleeding detected" if bleeding_info.get("severity") == "severe" else None,
                "suggested_action": "Apply bipolar coagulation" if bleeding_info.get("severity") != "severe" else "Assess source immediately"
            })
        
        # Check for tissue changes
        if frame_data.get("tissue_anomaly"):
            tissue_info = frame_data["tissue_anomaly"]
            anomalies.append({
                "type": "tissue_change",
                "description": tissue_info.get("description", "Unexpected tissue appearance"),
                "location": tissue_info.get("location"),
                "suggested_action": "Reassess anatomy with navigation"
            })
        
        # Check for instrument issues
        if frame_data.get("instrument_anomaly"):
            anomalies.append({
                "type": "instrument_issue",
                "description": frame_data["instrument_anomaly"],
                "suggested_action": "Check instrument integrity"
            })
        
        return anomalies
    
    async def _generate_next_step_suggestion(self, frame_data: Dict) -> Dict:
        """Generate context-aware next step suggestion."""
        suggestions = {
            SurgicalPhase.PREPARATION: {
                "next_step": "Verify patient positioning and complete surgical timeout",
                "rationale": "Ensure all safety checks completed before incision"
            },
            SurgicalPhase.EXPOSURE: {
                "next_step": "Identify key anatomical landmarks before proceeding",
                "rationale": "Confirm orientation with navigation system"
            },
            SurgicalPhase.APPROACH: {
                "next_step": "Carefully dissect toward target, preserving cortical vessels",
                "rationale": "Maintain visualization and hemostasis"
            },
            SurgicalPhase.RESECTION: {
                "next_step": "Continue systematic tumor removal, check margins periodically",
                "rationale": "Balance extent of resection with functional preservation"
            },
            SurgicalPhase.HEMOSTASIS: {
                "next_step": "Inspect resection cavity thoroughly before closure",
                "rationale": "Prevent postoperative hematoma"
            },
            SurgicalPhase.CLOSURE: {
                "next_step": "Ensure watertight dural closure",
                "rationale": "Prevent CSF leak"
            }
        }
        
        suggestion = suggestions.get(self.current_phase, {
            "next_step": "Assess current situation and proceed cautiously",
            "rationale": "Maintain situational awareness"
        })
        
        # Add context-specific modifications
        if frame_data.get("close_to_critical"):
            suggestion["next_step"] = "Slow down - approaching critical structure"
            suggestion["confidence"] = 0.95
        else:
            suggestion["confidence"] = 0.8
        
        return suggestion
    
    def get_navigation_summary(self) -> Dict:
        """Get summary of navigation session."""
        return {
            "procedure": self.procedure_type,
            "phases_completed": [p[0].value for p in self.phase_history],
            "structures_identified": list(self.identified_structures.keys()),
            "critical_alerts_total": len(self.critical_alerts),
            "navigation_accuracy_mm": self.navigation_accuracy_mm,
            "session_duration_minutes": (datetime.now() - self.phase_history[0][1]).total_seconds() / 60 if self.phase_history else 0
        }


# =============================================================================
# UNIFIED DEMONSTRATION SYSTEM
# =============================================================================

async def run_or_safety_demo():
    """Demonstrate OR Safety Monitoring with streaming output."""
    print("\n" + "="*80)
    print("ðŸ”´ REAL-TIME OR SAFETY MONITORING DEMONSTRATION")
    print("="*80)
    
    monitor = ORSafetyMonitor()
    
    # Simulate frame with potential issues
    test_frame = {
        "contamination_risks": [
            {"severity": "warning", "description": "Non-sterile sleeve near field", 
             "x": 0.6, "y": 0.3, "voice": "Sleeve warning", "action": "Adjust gown"},
            {"severity": "caution", "description": "Traffic in corridor", 
             "x": 0.9, "y": 0.5, "voice": "Door traffic", "action": "Minimize movement"}
        ],
        "detected_objects": [
            {"label": "surgeon_hand", "category": "sterile", "x": 0.5, "y": 0.5},
            {"label": "circulator_arm", "category": "non_sterile", "x": 0.7, "y": 0.3}
        ],
        "instruments": [
            {"id": "bipolar_1", "label": "Bipolar forceps", "state": "active", "x": 0.5, "y": 0.45, "confidence": 0.94},
            {"id": "suction_1", "label": "Suction", "state": "in_hand", "x": 0.48, "y": 0.52, "confidence": 0.91}
        ],
        "personnel": [
            {"role": "surgeon", "scrubbed": True, "x": 0.5, "y": 0.4},
            {"role": "first_assistant", "scrubbed": True, "x": 0.4, "y": 0.45},
            {"role": "circulator", "scrubbed": False, "x": 0.85, "y": 0.5}
        ],
        "critical_structures": [
            {"label": "motor_cortex", "x": 0.45, "y": 0.42, "safety_margin": 0.03}
        ],
        "instrument_tips": [
            {"label": "bipolar_tip", "x": 0.46, "y": 0.43}
        ]
    }
    
    print("\nðŸ“¡ Streaming frame analysis...")
    print("-"*60)
    
    async for update in monitor.analyze_frame_stream(test_frame, yield_interval_ms=200):
        update_type = update.get("type", "unknown")
        
        if update_type == "frame_start":
            print(f"\nâ±ï¸  Frame: {update['frame_id']}")
        
        elif update_type == "contamination_check":
            status = "âš ï¸  WARNINGS" if update.get("alerts") else "âœ… Clear"
            print(f"   Contamination: {status}")
            for alert in update.get("alerts", []):
                print(f"      - [{alert['severity']}] {alert['message']}")
        
        elif update_type == "sterile_field_status":
            integrity = update.get("integrity", "unknown")
            icon = "âœ…" if integrity == "intact" else "âŒ"
            print(f"   Sterile Field: {icon} {integrity.upper()}")
        
        elif update_type == "instrument_tracking":
            print(f"   Instruments: {update['count']} tracked")
            for inst in update.get("instruments", []):
                sterile = "âœ“" if inst.get("in_sterile_field") else "âœ—"
                print(f"      - {inst['label']}: {inst['state']} [{sterile}]")
        
        elif update_type == "personnel_status":
            personnel = update.get("personnel", {})
            print(f"   Personnel: {personnel.get('count', 0)} verified")
            for concern in personnel.get("concerns", []):
                print(f"      âš ï¸  {concern['issue']}")
        
        elif update_type == "proximity_alert":
            print(f"   âš ï¸  PROXIMITY ALERTS:")
            for alert in update.get("alerts", []):
                print(f"      ðŸ”´ {alert['message']}")
        
        elif update_type == "frame_complete":
            print(f"\n   â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”")
            print(f"   Processing: {update['processing_time_ms']}ms")
            print(f"   Safety Score: {update['safety_score']}/100")
            print(f"   Critical Alerts: {update['critical_alerts']}")
            if update.get("voice_alerts"):
                print(f"   ðŸ”Š Voice: {update['voice_alerts']}")
    
    print("\n" + "-"*60)
    print("Session Summary:", json.dumps(monitor.get_session_summary(), indent=2))


async def run_training_demo():
    """Demonstrate Surgical Training System with streaming feedback."""
    print("\n" + "="*80)
    print("ðŸŽ“ SURGICAL TRAINING & ASSESSMENT DEMONSTRATION")
    print("="*80)
    
    trainer = SurgicalTrainingSystem(
        trainee_id="DR_TRAINEE_001",
        procedure_type="craniotomy_tumor_resection"
    )
    
    print(f"\nðŸ“‹ Procedure: Craniotomy for Tumor Resection")
    print(f"   Steps: {len(trainer.procedure_steps)}")
    print(f"   Trainee: {trainer.trainee_id}")
    
    # Simulate training on first 3 steps
    for step_num in range(3):
        current_step = trainer.procedure_steps[step_num]
        print(f"\n{'â”€'*60}")
        print(f"ðŸ“Œ STEP {current_step.step_number}: {current_step.name}")
        print(f"   {'âš ï¸  CRITICAL STEP' if current_step.critical else ''}")
        print(f"   {current_step.description}")
        
        # Simulate frame for this step
        test_frame = {
            "instruments": [{"label": inst, "state": "in_hand", "x": 0.5, "y": 0.5} 
                          for inst in current_step.required_instruments],
            "completion_indicators": {"step_complete": True, "score": random.uniform(75, 95)}
        }
        
        print(f"\n   ðŸ“¡ Real-time assessment...")
        
        async for update in trainer.analyze_step_stream(test_frame, yield_interval_ms=150):
            update_type = update.get("type")
            
            if update_type == "instrument_check":
                all_ready = update.get("all_ready", False)
                icon = "âœ…" if all_ready else "âš ï¸"
                print(f"      {icon} Instruments: {'Ready' if all_ready else 'Missing: ' + ', '.join(update.get('missing', []))}")
            
            elif update_type == "safety_verification":
                all_passed = update.get("all_passed", False)
                icon = "âœ…" if all_passed else "âš ï¸"
                print(f"      {icon} Safety checks: {'Passed' if all_passed else 'Issues detected'}")
            
            elif update_type == "technique_assessment":
                score = update.get("weighted_score", 0)
                print(f"      ðŸ“Š Technique score: {score:.1f}/100")
            
            elif update_type == "error_detection":
                if update.get("errors"):
                    print(f"      âŒ Errors: {[e['error_type'] for e in update['errors']]}")
            
            elif update_type == "realtime_feedback":
                feedback = update.get("feedback", {})
                if feedback.get("voice_message"):
                    print(f"      ðŸ”Š Feedback: {feedback['voice_message']}")
            
            elif update_type == "step_analysis_complete":
                can_proceed = update.get("can_proceed", False)
                score = update.get("completion_score", 0)
                icon = "âœ…" if can_proceed else "âš ï¸"
                print(f"      {icon} Step complete: {score:.1f}% - {'Proceed' if can_proceed else 'Review needed'}")
        
        trainer.advance_step()
    
    print("\n" + "â”€"*60)
    print("\nðŸ“Š SESSION REPORT")
    print("â”€"*60)
    report = trainer.get_session_report()
    print(f"   Overall Score: {report['overall_score']}/100")
    print(f"   Grade: {report['grade']}")
    print(f"   Steps Completed: {report['steps_completed']}/{report['total_steps']}")
    print(f"\n   Metrics:")
    for metric, value in report['metrics'].items():
        bar = "â–ˆ" * int(value / 10) + "â–‘" * (10 - int(value / 10))
        print(f"      {metric.capitalize():12} [{bar}] {value}")
    print(f"\n   Recommendations:")
    for rec in report['recommendations']:
        print(f"      â€¢ {rec}")
    print(f"\n   Certification Eligible: {'âœ… YES' if report['certification_eligible'] else 'âŒ NO'}")


async def run_navigation_demo():
    """Demonstrate Intraoperative Navigation Assistance."""
    print("\n" + "="*80)
    print("ðŸ§­ INTRAOPERATIVE NAVIGATION ASSISTANCE DEMONSTRATION")
    print("="*80)
    
    navigator = IntraoperativeNavigationAssistant(
        procedure_type="craniotomy_tumor_resection",
        planned_trajectory={
            "entry": {"x": 0.35, "y": 0.25},
            "target": {"x": 0.55, "y": 0.65}
        }
    )
    
    print(f"\nðŸ“ Procedure: {navigator.procedure_type}")
    print(f"   Critical structures monitored: {len(navigator.critical_structures)}")
    print(f"   Navigation accuracy: {navigator.navigation_accuracy_mm}mm")
    
    # Simulate navigation frames
    frames = [
        {
            "anatomical_structures": [
                {"label": "tumor_margin", "x": 0.52, "y": 0.58, "confidence": 0.91, "category": "pathology"},
                {"label": "sulcus", "x": 0.48, "y": 0.45, "confidence": 0.87, "category": "anatomy"}
            ],
            "instrument_tip": {"x": 0.45, "y": 0.48, "label": "CUSA"},
            "critical_structures": {
                "motor_cortex": {"x": 0.38, "y": 0.42},
                "mca_branch": {"x": 0.52, "y": 0.40}
            },
            "phase_indicators": {"tumor_visible": True},
            "close_to_critical": False
        },
        {
            "anatomical_structures": [
                {"label": "tumor_margin", "x": 0.54, "y": 0.60, "confidence": 0.93, "category": "pathology"}
            ],
            "instrument_tip": {"x": 0.51, "y": 0.55, "label": "CUSA"},
            "critical_structures": {
                "motor_cortex": {"x": 0.38, "y": 0.42},
                "cortical_vein": {"x": 0.53, "y": 0.52}
            },
            "phase_indicators": {"tumor_visible": True},
            "bleeding_detected": {"severity": "mild", "location": {"x": 0.52, "y": 0.54}},
            "close_to_critical": True
        }
    ]
    
    for i, frame in enumerate(frames):
        print(f"\n{'â”'*60}")
        print(f"ðŸ“¡ NAVIGATION FRAME {i+1}")
        print(f"{'â”'*60}")
        
        async for update in navigator.analyze_navigation_frame(frame, yield_interval_ms=100):
            update_type = update.get("type")
            
            if update_type == "nav_frame_start":
                print(f"   Phase: {update['current_phase']}")
            
            elif update_type == "structure_identification":
                print(f"   Structures: {update['count']} identified")
                for s in update.get("structures", []):
                    print(f"      â€¢ {s['label']} ({s['confidence']:.0%})")
            
            elif update_type == "distance_update":
                dist = update.get("distance_to_target_mm", "N/A")
                dev = update.get("trajectory_deviation_mm", "N/A")
                depth = update.get("depth_percentage", 0)
                on_traj = "âœ“" if update.get("on_trajectory") else "âœ—"
                print(f"   ðŸ“ Distance to target: {dist}mm")
                print(f"   ðŸ“ Trajectory deviation: {dev}mm [{on_traj}]")
                print(f"   ðŸ“Š Depth: {depth:.0f}%")
            
            elif update_type == "proximity_warning":
                print(f"   âš ï¸  PROXIMITY WARNING:")
                for alert in update.get("alerts", []):
                    print(f"      ðŸ”´ {alert['message']}")
                if update.get("voice_alert"):
                    print(f"      ðŸ”Š {update['voice_alert']}")
            
            elif update_type == "proximity_clear":
                nearest = update.get("nearest", {})
                if nearest:
                    print(f"   âœ… Safe - Nearest: {nearest['structure']} ({nearest['distance_mm']}mm)")
            
            elif update_type == "anomaly_detected":
                print(f"   âš ï¸  ANOMALIES:")
                for anomaly in update.get("anomalies", []):
                    print(f"      â€¢ {anomaly['type']}: {anomaly.get('suggested_action', 'Assess')}")
            
            elif update_type == "guidance":
                print(f"   ðŸ’¡ Guidance ({update['confidence']:.0%}):")
                print(f"      {update['suggestion']}")
            
            elif update_type == "nav_frame_complete":
                print(f"   â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€")
                print(f"   â±ï¸  Processing: {update['processing_time_ms']}ms")
                print(f"   ðŸŽ¯ Accuracy: {update['navigation_accuracy_mm']}mm")
    
    print("\n" + "â”€"*60)
    print("\nðŸ“Š NAVIGATION SUMMARY")
    summary = navigator.get_navigation_summary()
    print(f"   Structures tracked: {len(summary['structures_identified'])}")
    print(f"   Critical alerts: {summary['critical_alerts_total']}")
    print(f"   Duration: {summary['session_duration_minutes']:.1f} minutes")


async def main():
    """Run all demonstrations."""
    print("""
â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—
â•‘                                                                                                      â•‘
â•‘                     â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•—â–ˆâ–ˆâ•—      â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•— â–ˆâ–ˆâ•—   â–ˆâ–ˆâ•—â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•— â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•—                                 â•‘
â•‘                    â–ˆâ–ˆâ•”â•â•â•â•â•â–ˆâ–ˆâ•‘     â–ˆâ–ˆâ•”â•â•â–ˆâ–ˆâ•—â–ˆâ–ˆâ•‘   â–ˆâ–ˆâ•‘â–ˆâ–ˆâ•”â•â•â–ˆâ–ˆâ•—â–ˆâ–ˆâ•”â•â•â•â•â•                                 â•‘
â•‘                    â–ˆâ–ˆâ•‘     â–ˆâ–ˆâ•‘     â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•‘â–ˆâ–ˆâ•‘   â–ˆâ–ˆâ•‘â–ˆâ–ˆâ•‘  â–ˆâ–ˆâ•‘â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•—                                   â•‘
â•‘                    â–ˆâ–ˆâ•‘     â–ˆâ–ˆâ•‘     â–ˆâ–ˆâ•”â•â•â–ˆâ–ˆâ•‘â–ˆâ–ˆâ•‘   â–ˆâ–ˆâ•‘â–ˆâ–ˆâ•‘  â–ˆâ–ˆâ•‘â–ˆâ–ˆâ•”â•â•â•                                   â•‘
â•‘                    â•šâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•—â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•—â–ˆâ–ˆâ•‘  â–ˆâ–ˆâ•‘â•šâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•”â•â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•”â•â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•—                                 â•‘
â•‘                     â•šâ•â•â•â•â•â•â•šâ•â•â•â•â•â•â•â•šâ•â•  â•šâ•â• â•šâ•â•â•â•â•â• â•šâ•â•â•â•â•â• â•šâ•â•â•â•â•â•â•                                 â•‘
â•‘                                                                                                      â•‘
â•‘                    NEUROSURGICAL AI PLATFORM - REAL-TIME SYSTEMS                                     â•‘
â•‘                                                                                                      â•‘
â•‘     Capabilities that EXCEED Gemini Robotics-ER for Neurosurgical Applications:                      â•‘
â•‘                                                                                                      â•‘
â•‘     ðŸ”´ OR Safety Monitoring    - Streaming contamination & sterile field analysis                    â•‘
â•‘     ðŸŽ“ Surgical Training       - Real-time technique assessment & competency tracking                â•‘
â•‘     ðŸ§­ Navigation Assistance   - Critical proximity, phase detection, anomaly alerts                 â•‘
â•‘                                                                                                      â•‘
â•‘     Features:                                                                                        â•‘
â•‘     â€¢ Async streaming for sub-second latency (simulated real-time feel)                              â•‘
â•‘     â€¢ Voice-ready alerts for TTS integration                                                         â•‘
â•‘     â€¢ Comprehensive procedure libraries (craniotomy, transsphenoidal, DBS)                           â•‘
â•‘     â€¢ Safety scoring with actionable recommendations                                                 â•‘
â•‘     â€¢ Extended thinking for complex surgical decisions                                               â•‘
â•‘                                                                                                      â•‘
â•‘     For Dr. Matheus Machado Rech - Advancing Neurosurgical Innovation                                â•‘
â•‘                                                                                                      â•‘
â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    """)
    
    # Run all demos
    await run_or_safety_demo()
    await run_training_demo()
    await run_navigation_demo()
    
    print("\n" + "="*80)
    print("âœ… ALL DEMONSTRATIONS COMPLETE")
    print("="*80)
    print("""
Next Steps for Production Integration:

1. REAL-TIME STREAMING
   - Connect to actual video feed via Claude API with streaming
   - Use Claude's vision capabilities for frame analysis
   - Implement WebSocket fallback for persistent connections

2. VOICE INTEGRATION
   - Feed voice_message outputs to TTS system (ElevenLabs API)
   - Implement voice command input for hands-free operation
   - Priority queuing for critical alerts

3. HARDWARE INTEGRATION
   - Connect to surgical navigation systems (Medtronic, BrainLab)
   - Integrate with surgical robots (ROSA, Neuromate)
   - Real-time instrument tracking via OR cameras

4. MCP SERVERS
   - Create MCP server for navigation system integration
   - Build MCP server for surgical video analysis
   - Develop MCP server for training database

5. SKILLS ENHANCEMENT
   - Extend neuroimaging-segmentation skill for real-time analysis
   - Create contamination-detection skill with OR-specific training
   - Build surgical-instrument-identification skill

Ready for the future of AI-assisted neurosurgery! ðŸ§ ðŸ¤–
    """)


if __name__ == "__main__":
    asyncio.run(main())
